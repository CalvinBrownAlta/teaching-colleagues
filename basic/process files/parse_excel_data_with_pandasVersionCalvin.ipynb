{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse pedestrian volumes from an Excel-based Turning Movement Count\n",
    "\n",
    "We have a folder full of Excel count data and companion PDFs. We need to parse each one to pull out a Pedestrian-specific volume number that we can then use to scale point sizes on a GIS map.\n",
    "\n",
    "Things to note:\n",
    "- Data does not start on Row 1\n",
    "- There are typically 4 columns with Ped data, but there could be non-standard intersections with more or fewer legs\n",
    "\n",
    "### Use jupyter to prototype a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = '/Users/calvindechicago/PycharmProjects/AltaWork/teaching-colleagues/Counts/Counts/Count Reports 6-17-19'\n",
    "test_file = os.path.join(data_folder, \"1 LICK MILL BLVD & TASMAN DR.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/Users/calvindechicago/PycharmProjects/AltaWork/teaching-colleagues/Counts/Counts/Count Reports 6-17-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file starting at line 10\n",
    "df = pd.read_excel(test_file, sheet_name=\"Vehicles\", header=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable that will hold the total across all \"Peds\" columns\n",
    "running_total = 0\n",
    "\n",
    "# Get a list of all \"Peds\" column names\n",
    "#ped_cols = [x for x in df.columns if \"Peds\" in x]\n",
    "\n",
    "#Above list comprehension as a for loop\n",
    "ped_cols = []\n",
    "for x in df.columns: \n",
    "    if \"Peds\" in x:\n",
    "        ped_cols.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Peds', 'Peds.1', 'Peds.2', 'Peds.3']\n"
     ]
    }
   ],
   "source": [
    "#see new value of ped_cols\n",
    "print(ped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peds\n",
      "Peds.1\n",
      "Peds.2\n",
      "Peds.3\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "# For each column, get the sum and add it to the running total\n",
    "for col in ped_cols:\n",
    "    col_total = df[col].sum()\n",
    "    \n",
    "    print(col)\n",
    "\n",
    "    running_total += col_total\n",
    "        \n",
    "print(running_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have a working solution, compartmentalize it within a function:\n",
    "\n",
    "Notice that I've left a few ``TODO`` items in there. Figure out how to add those in after you've reviewed the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "=================\n",
      "=================\n",
      "=================\n",
      "                     right  thru  left  peds  right.1  thru.1  left.1  peds.1  \\\n",
      "start_time                                                                      \n",
      "2019-09-09 05:00:00      0     0     0     1        0      12       3       0   \n",
      "2019-09-09 05:15:00      0     0     0     0        0      18       2       0   \n",
      "2019-09-09 05:30:00      0     0     0     0        3      21       6       0   \n",
      "\n",
      "                     right.2  thru.2  left.2  peds.2  right.3  thru.3  left.3  \\\n",
      "start_time                                                                      \n",
      "2019-09-09 05:00:00        4       1       1       0        2       2       0   \n",
      "2019-09-09 05:15:00        8       0      10       0        4      11       2   \n",
      "2019-09-09 05:30:00        7       0      13       0        1      11       0   \n",
      "\n",
      "                     peds.3  \n",
      "start_time                   \n",
      "2019-09-09 05:00:00       0  \n",
      "2019-09-09 05:15:00       0  \n",
      "2019-09-09 05:30:00       0  \n",
      "                     right  thru  left  peds  right.1  thru.1  left.1  peds.1  \\\n",
      "start_time                                                                      \n",
      "2019-09-09 21:15:00      0     1     0     2        1      42      23       0   \n",
      "2019-09-09 21:30:00      0     0     0     2        0      33      26       0   \n",
      "2019-09-09 21:45:00      1     0     0     1        0      25      27       0   \n",
      "\n",
      "                     right.2  thru.2  left.2  peds.2  right.3  thru.3  left.3  \\\n",
      "start_time                                                                      \n",
      "2019-09-09 21:15:00       39       0       4       1       19      53       0   \n",
      "2019-09-09 21:30:00       35       0       5       4       22      45       2   \n",
      "2019-09-09 21:45:00       20       0       5       0       13      38       1   \n",
      "\n",
      "                     peds.3  \n",
      "start_time                   \n",
      "2019-09-09 21:15:00       2  \n",
      "2019-09-09 21:30:00       1  \n",
      "2019-09-09 21:45:00       1  \n",
      "=================\n",
      "Types\n",
      "right      int64\n",
      "thru       int64\n",
      "left       int64\n",
      "peds       int64\n",
      "right.1    int64\n",
      "thru.1     int64\n",
      "left.1     int64\n",
      "peds.1     int64\n",
      "right.2    int64\n",
      "thru.2     int64\n",
      "left.2     int64\n",
      "peds.2     int64\n",
      "right.3    int64\n",
      "thru.3     int64\n",
      "left.3     int64\n",
      "peds.3     int64\n",
      "dtype: object\n",
      "=================\n",
      "Values\n",
      "[[ 0  0  0 ...  2  0  0]\n",
      " [ 0  0  0 ... 11  2  0]\n",
      " [ 0  0  0 ... 11  0  0]\n",
      " ...\n",
      " [ 0  1  0 ... 53  0  2]\n",
      " [ 0  0  0 ... 45  2  1]\n",
      " [ 1  0  0 ... 38  1  1]]\n",
      "=================\n",
      "Columns\n",
      "Index(['right', 'thru', 'left', 'peds', 'right.1', 'thru.1', 'left.1',\n",
      "       'peds.1', 'right.2', 'thru.2', 'left.2', 'peds.2', 'right.3', 'thru.3',\n",
      "       'left.3', 'peds.3'],\n",
      "      dtype='object')\n",
      "=================\n",
      "Index\n",
      "DatetimeIndex(['2019-09-09 05:00:00', '2019-09-09 05:15:00',\n",
      "               '2019-09-09 05:30:00', '2019-09-09 05:45:00',\n",
      "               '2019-09-09 06:00:00', '2019-09-09 06:15:00',\n",
      "               '2019-09-09 06:30:00', '2019-09-09 06:45:00',\n",
      "               '2019-09-09 07:00:00', '2019-09-09 07:15:00',\n",
      "               '2019-09-09 07:30:00', '2019-09-09 07:45:00',\n",
      "               '2019-09-09 08:00:00', '2019-09-09 08:15:00',\n",
      "               '2019-09-09 08:30:00', '2019-09-09 08:45:00',\n",
      "               '2019-09-09 09:00:00', '2019-09-09 09:15:00',\n",
      "               '2019-09-09 09:30:00', '2019-09-09 09:45:00',\n",
      "               '2019-09-09 10:00:00', '2019-09-09 10:15:00',\n",
      "               '2019-09-09 10:30:00', '2019-09-09 10:45:00',\n",
      "               '2019-09-09 11:00:00', '2019-09-09 11:15:00',\n",
      "               '2019-09-09 11:30:00', '2019-09-09 11:45:00',\n",
      "               '2019-09-09 12:00:00', '2019-09-09 12:15:00',\n",
      "               '2019-09-09 12:30:00', '2019-09-09 12:45:00',\n",
      "               '2019-09-09 13:00:00', '2019-09-09 13:15:00',\n",
      "               '2019-09-09 13:30:00', '2019-09-09 13:45:00',\n",
      "               '2019-09-09 14:00:00', '2019-09-09 14:15:00',\n",
      "               '2019-09-09 14:30:00', '2019-09-09 14:45:00',\n",
      "               '2019-09-09 15:00:00', '2019-09-09 15:15:00',\n",
      "               '2019-09-09 15:30:00', '2019-09-09 15:45:00',\n",
      "               '2019-09-09 16:00:00', '2019-09-09 16:15:00',\n",
      "               '2019-09-09 16:30:00', '2019-09-09 16:45:00',\n",
      "               '2019-09-09 17:00:00', '2019-09-09 17:15:00',\n",
      "               '2019-09-09 17:30:00', '2019-09-09 17:45:00',\n",
      "               '2019-09-09 18:00:00', '2019-09-09 18:15:00',\n",
      "               '2019-09-09 18:30:00', '2019-09-09 18:45:00',\n",
      "               '2019-09-09 19:00:00', '2019-09-09 19:15:00',\n",
      "               '2019-09-09 19:30:00', '2019-09-09 19:45:00',\n",
      "               '2019-09-09 20:00:00', '2019-09-09 20:15:00',\n",
      "               '2019-09-09 20:30:00', '2019-09-09 20:45:00',\n",
      "               '2019-09-09 21:00:00', '2019-09-09 21:15:00',\n",
      "               '2019-09-09 21:30:00', '2019-09-09 21:45:00'],\n",
      "              dtype='datetime64[ns]', name='start_time', freq=None)\n",
      "=================\n",
      "Columns\n",
      "Index(['right', 'thru', 'left', 'peds', 'right.1', 'thru.1', 'left.1',\n",
      "       'peds.1', 'right.2', 'thru.2', 'left.2', 'peds.2', 'right.3', 'thru.3',\n",
      "       'left.3', 'peds.3'],\n",
      "      dtype='object')\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=================\")\n",
    "print(type(df))\n",
    "print(\"=================\")\n",
    "print(\"=================\")\n",
    "print(\"=================\")\n",
    "print(df.head(3))\n",
    "print(df.tail(3))\n",
    "print(\"=================\")\n",
    "print(\"Types\")\n",
    "print(df.dtypes)\n",
    "print(\"=================\")\n",
    "print(\"Values\")\n",
    "print(df.values)\n",
    "print(\"=================\")\n",
    "print(\"Columns\")\n",
    "print(df.columns)\n",
    "print(\"=================\")\n",
    "print(\"Index\")\n",
    "print(df.index)\n",
    "print(\"=================\")\n",
    "df.columns = df.columns.str.lower().str.replace(' ','_')\n",
    "print(\"Columns\")\n",
    "print(df.columns)\n",
    "print(\"=================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time    datetime64[ns]\n",
      "right                  int64\n",
      "thru                   int64\n",
      "left                   int64\n",
      "peds                   int64\n",
      "right.1                int64\n",
      "thru.1                 int64\n",
      "left.1                 int64\n",
      "peds.1                 int64\n",
      "right.2                int64\n",
      "thru.2                 int64\n",
      "left.2                 int64\n",
      "peds.2                 int64\n",
      "right.3                int64\n",
      "thru.3                 int64\n",
      "left.3                 int64\n",
      "peds.3                 int64\n",
      "dtype: object\n",
      "0      5\n",
      "1      5\n",
      "2      5\n",
      "3      5\n",
      "4      6\n",
      "      ..\n",
      "63    20\n",
      "64    21\n",
      "65    21\n",
      "66    21\n",
      "67    21\n",
      "Name: start_time, Length: 68, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.start_time = df.start_time.astype('datetime64[ns]')\n",
    "print(df.dtypes)\n",
    "print(df.start_time.dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 6, 6, 6, 6]\n",
      "[7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#List Comprehension that iterates on starttime column\n",
    "timebucket =[x for x in df.start_time.dt.hour if x > 4 and x < 7]\n",
    "timebucket_morningrush =[x for x in df.start_time.dt.hour if x > 6 and x < 10]\n",
    "print(timebucket)\n",
    "print(timebucket_morningrush)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "betweentime =[x for x in df.start_time if df.start_time.between_time('0:45', '0:15')]\n",
    "df = df.set_index('datetime')\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.indexer_between_time.html#pandas.DatetimeIndex.indexer_between_time\n",
    "great pandas time tutorial\n",
    "https://www.youtube.com/watch?v=yCgJGsg0Xa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatetimeIndex' object has no attribute 'between_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-521a0837d3c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbtimetest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetween_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5:45'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'6:15'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbtimetest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatetimeIndex' object has no attribute 'between_time'"
     ]
    }
   ],
   "source": [
    "btimetest = df.index.between_time('5:45', '6:15')\n",
    "btimetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do all the above as a function\n",
    "\n",
    "def get_ped_total(excel_count_file):\n",
    "    # Read the file starting at line 10\n",
    "    df = pd.read_excel(excel_count_file, sheet_name=\"Vehicles\", header=9)\n",
    "\n",
    "    # Make a variable that will hold the total across all \"Peds\" columns\n",
    "    daily_total = 0\n",
    "\n",
    "    # Get a list of all \"Peds\" column names\n",
    "    ped_cols = [x for x in df.columns if \"Peds\" in x]\n",
    "\n",
    "    # For each column, get the sum and add it to the daily total\n",
    "    for col in ped_cols:\n",
    "        col_total = df[col].sum()\n",
    "\n",
    "        daily_total += col_total\n",
    "        \n",
    "    # TODO: parse out a few time buckets (i.e. AM peak, midday, PM peak)\n",
    "    # ...\n",
    "    \n",
    "    # TODO: modify the return value so that the function returns the daily total along with the time bucket totals\n",
    "    # ...\n",
    "    \n",
    "    return daily_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're ready to iterate over all Excel files and pull results out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(data_folder):\n",
    "    xls_path = os.path.join(xlsx_folder, f)\n",
    "    total = get_ped_total(xls_path)\n",
    "    \n",
    "    print(total, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Macintosh HD⁩ ▸ ⁨Users⁩ ▸ ⁨calvindechicago⁩ ▸ ⁨PycharmProjects⁩ ▸ ⁨AltaWork⁩ ▸ ⁨teaching-colleagues⁩ ▸ ⁨Counts⁩ ▸ ⁨Counts⁩ ▸ ⁨Count Reports 6-17-19⁩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``TODO``\n",
    "\n",
    "- Iterate over all files, getting full day and time bucket data\n",
    "- Wrangle all results into a ``pandas.DataFrame``. Each location (/excel file) becomes a row in this table.\n",
    "- Save this dataframe to ``.csv``"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
